{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99_2rPCJrNfK"
   },
   "source": [
    "## Exercise 2: Use Gradient Boost for Regression\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Use the Dataset File to train your model\n",
    "- Use the Test File to generate your results\n",
    "- Use the Sample Submission file to generate the same format\n",
    "Submit your results to:\n",
    "https://www.kaggle.com/competitions/playground-series-s4e12/overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "id": "R_se3V8gftVL"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eCNNEXIhftVN"
   },
   "source": [
    "## Dataset\n",
    "Train, test and sample submission file can be found in this link\n",
    "https://www.kaggle.com/competitions/playground-series-s4e12/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rjhN8ODcVYxH"
   },
   "source": [
    "## 1. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "tEcU-yJmVZwR",
    "outputId": "7b3710a3-8397-4090-f530-f5bc6b2cc6f9"
   },
   "outputs": [],
   "source": [
    "# put your answer here\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "dt = pd.read_csv(\"test.csv\")\n",
    "sf = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "df['source'] = 'train'\n",
    "dt['source'] = 'test'\n",
    "\n",
    "data = pd.concat([df, dt], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlMLKDF_rvUM"
   },
   "source": [
    "## 2. Perform Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "id": "Z1KdsdzALyw3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nn/36lhgshn7tq43kb5n5y3qkfm0000gn/T/ipykernel_11108/3089462261.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[num].fillna(data[num].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data['Policy Start Date'] = pd.to_datetime(data['Policy Start Date'], errors='coerce')\n",
    "data['year'] = data['Policy Start Date'].dt.year\n",
    "data['month'] = data['Policy Start Date'].dt.month\n",
    "data['day'] = data['Policy Start Date'].dt.day\n",
    "data['hour'] = data['Policy Start Date'].dt.hour\n",
    "data['minute'] = data['Policy Start Date'].dt.minute\n",
    "data['second'] = data['Policy Start Date'].dt.second\n",
    "\n",
    "most_frequent_date = data['Policy Start Date'].mode()[0]\n",
    "data['Policy Start Date'] = data['Policy Start Date'].fillna(most_frequent_date)\n",
    "\n",
    "data.drop(['Policy Start Date'], inplace=True, axis=1)\n",
    "\n",
    "cat = data.select_dtypes(include=['object']).columns.tolist()\n",
    "num = data.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "\n",
    "num_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data[num] = num_imputer.fit_transform(data[num])\n",
    "\n",
    "cat_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "data[cat] = cat_imputer.fit_transform(data[cat])\n",
    "        \n",
    "data[num].fillna(data[num].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "EsNq5ngR11VC"
   },
   "outputs": [],
   "source": [
    "df = data[data['source'] == 'train'].drop(columns=['id','source'])\n",
    "dt = data[data['source'] == 'test'].drop(columns=['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "id": "B8hZcDDaksqu"
   },
   "outputs": [],
   "source": [
    "X = df.drop(columns=['Premium Amount'])\n",
    "y = df['Premium Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = X.select_dtypes(include=['object']).columns.tolist()\n",
    "num = X.select_dtypes(include=['float64', 'int64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "id": "fWAKu3gFcfJi"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(), cat),\n",
    "        (\"num\", StandardScaler(), num)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "SNmtblgnc0qc"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": 500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-z7RFsxWLHM"
   },
   "source": [
    "## 3. Create a Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "6GZ2sLPEI54f"
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "id": "PuJFYWuSWNvB"
   },
   "outputs": [],
   "source": [
    "# put your answer here\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "UnqsSxsiv5HC"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8n-ScOLqze60"
   },
   "source": [
    "## 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "id": "L4R608WJ1iiX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yscalify/Files/3RD YEAR - 2ND TERM/CCADMACL/activities/.venv/lib/python3.13/site-packages/xgboost/core.py:158: UserWarning: [13:02:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"loss\", \"min_samples_split\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkAsAi29WiDq"
   },
   "source": [
    "## 5. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "8L0zJYBfWiVX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared log error: 1.1589541934553096\n"
     ]
    }
   ],
   "source": [
    "# put your answer here\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_log_error\n",
    "\n",
    "rmsle = root_mean_squared_log_error(y_test, y_pred)\n",
    "\n",
    "print(\"Root mean squared log error:\", rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6UAAMyepmHi"
   },
   "source": [
    "## Generate Submission File\n",
    "\n",
    "Choose the model that has the best performance to generate a submission file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "id": "HrelEEFJpjzI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created: submission_file.csv\n"
     ]
    }
   ],
   "source": [
    "id = sf.pop('id')\n",
    "y_pred = pipeline.predict(dt.drop('id', axis=1))\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': id,\n",
    "    'Premium Amount': y_pred\n",
    "})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_file.csv', index=False)\n",
    "print(\"Submission file created: submission_file.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
